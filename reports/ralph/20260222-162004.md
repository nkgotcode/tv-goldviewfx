# Ralph Run 2026-02-22 16:20:04

## What Changed
- Extended evaluation contracts to accept Nautilus/reward controls from dashboard: `interval`, `leverage`, `takerFeeBps`, `slippageBps`, `fundingWeight`, `drawdownPenalty`, and structured walk-forward config.
- Added evaluation provenance capture in dataset build path: requested pair vs resolved BingX symbol/ticker, candidate pairs, source tables, row counts, data fields, and live-fetch details.
- Merged provenance + run parameters into persisted evaluation `metadata.parameters` / `metadata.dataset_provenance` for auditability.
- Passed `interval` through backend RL client into RL-service evaluation endpoint and Nautilus backtest runner.
- Updated `/rl-evaluations` dashboard to edit Nautilus settings and display resolved ticker/symbol, interval used, source tables, and data fields.
- De-duplicated "All pairs" evaluation execution by resolved BingX symbol token (so alias pairs do not run twice).

## Proof Run
- `cd backend && bun test --preload ./tests/setup.ts tests/unit/evaluation_service.test.ts tests/integration/rl_evaluations.test.ts`
- `cd backend/rl-service && uv run pytest tests/integration/test_evaluations_api.py tests/integration/test_evaluation_api.py -q`
- `cd frontend && bun run test ./tests/HomePage.test.tsx`

## Open Risks
- Full frontend production build is currently blocked by a pre-existing unrelated type error in `frontend/src/app/library/page.tsx` (`CrudFilter` operator typing).
- DB-backed integration coverage for RL evaluations remains gated without `DB_TEST_ENABLED=true`.

## Next Item
- Add persisted operator-configurable defaults for evaluation/Nautilus settings (not just per-run form values) and expose them through an agent config API.
